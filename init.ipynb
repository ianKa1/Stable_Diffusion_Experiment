{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80642a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaimao/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kaimao/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:07<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionModel(\n",
      "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (time_proj): Timesteps()\n",
      "  (time_embedding): TimestepEmbedding(\n",
      "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "    (act): SiLU()\n",
      "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (down_blocks): ModuleList(\n",
      "    (0): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleList(\n",
      "    (0): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-2): 3 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid_block): UNetMidBlock2DCrossAttn(\n",
      "    (attentions): ModuleList(\n",
      "      (0): Transformer2DModel(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn1): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn2): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (ff): FeedForward(\n",
      "              (net): ModuleList(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (resnets): ModuleList(\n",
      "      (0-1): 2 x ResnetBlock2D(\n",
      "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "  (conv_act): SiLU()\n",
      "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import os\n",
    "import transformers\n",
    "\n",
    "model_id = \"sd-legacy/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"mps\")\n",
    "\n",
    "print(pipe.unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a4a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:59<00:00,  2.39s/it]\n",
      "100%|██████████| 50/50 [02:16<00:00,  2.73s/it]\n",
      "100%|██████████| 50/50 [02:22<00:00,  2.85s/it]\n",
      "100%|██████████| 50/50 [02:34<00:00,  3.09s/it]\n",
      "100%|██████████| 50/50 [02:24<00:00,  2.88s/it]\n",
      "100%|██████████| 50/50 [02:32<00:00,  3.05s/it]\n",
      "100%|██████████| 50/50 [02:31<00:00,  3.04s/it]\n",
      "100%|██████████| 50/50 [02:35<00:00,  3.12s/it]\n",
      "100%|██████████| 50/50 [01:49<00:00,  2.20s/it]\n",
      "100%|██████████| 50/50 [01:14<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "spatial = [\n",
    "    \"a chicken on the left of a car\",\n",
    "    \"a person on the left of a cow\",\n",
    "    \"a horse on the right of a man\",\n",
    "    \"a man on side of a cat\",\n",
    "    \"a chicken near a book\",\n",
    "    \"a bicycle on the right of a girl\",\n",
    "    \"a dog next to a phone\",\n",
    "    \"a sheep next to a bicycle\",\n",
    "    \"a pig on the bottom of a candle\",\n",
    "    \"a butterfly on the left of a phone\"\n",
    "]\n",
    "\n",
    "output_dir = \"spatail_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for prompt in spatial:\n",
    "    image = pipe(prompt).images[0]  \n",
    "    image.save(f\"./{output_dir}/{prompt}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67019600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Photorealistic style, 85mm lens, shallow depth of field. Photorealistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Studio Ghibli anime style, soft watercolor textures, expressive eyes. Studio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Black-and-white manga style, crisp line art, screentone shading. Black-and-white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Impressionist oil painting style, visible brush strokes, warm color palette. Impressionist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Cyberpunk neon style, pink and blue glowing lights, chrome reflections. Cyberpunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Futuristic sci-fi illustration style, holographic lighting, metallic accents. Futuristic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Watercolor painting style, soft bleeding edges, gentle pastel tones. Watercolor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Picasso cubism style, abstract geometric forms, distorted shapes. Picasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Van Gogh style, swirling brush strokes, high contrast colors. Van\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:00<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.Vaporwave synthwave style, neon purples and blues, retro 80s atmosphere. Vaporwave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:58<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "identity_description = \"A young woman with short black hair, round glasses, soft smile, wearing a white sweater, sitting by a window with warm sunlight.\"\n",
    "style_lists = [\n",
    "    \"Photorealistic style, 85mm lens, shallow depth of field.\",\n",
    "    \"Studio Ghibli anime style, soft watercolor textures, expressive eyes.\",\n",
    "    \"Black-and-white manga style, crisp line art, screentone shading.\",\n",
    "    \"Impressionist oil painting style, visible brush strokes, warm color palette.\",\n",
    "    \"Cyberpunk neon style, pink and blue glowing lights, chrome reflections.\",\n",
    "    \"Futuristic sci-fi illustration style, holographic lighting, metallic accents.\",\n",
    "    \"Watercolor painting style, soft bleeding edges, gentle pastel tones.\",\n",
    "    \"Picasso cubism style, abstract geometric forms, distorted shapes.\",\n",
    "    \"Van Gogh style, swirling brush strokes, high contrast colors.\",\n",
    "    \"Vaporwave synthwave style, neon purples and blues, retro 80s atmosphere.\"\n",
    "]\n",
    "\n",
    "for style in style_lists:\n",
    "    prompt = identity_description + style\n",
    "    title = style.split()[0]\n",
    "    print(prompt, title)\n",
    "    image = pipe(prompt).images[0]  \n",
    "    image.save(f\"{title}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c3626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:52<00:00,  1.06s/it]\n",
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n",
      "100%|██████████| 50/50 [00:59<00:00,  1.19s/it]\n",
      "100%|██████████| 50/50 [00:59<00:00,  1.18s/it]\n",
      "100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n",
      "100%|██████████| 50/50 [01:02<00:00,  1.24s/it]\n",
      "100%|██████████| 50/50 [01:02<00:00,  1.25s/it]\n",
      "100%|██████████| 50/50 [01:05<00:00,  1.31s/it]\n",
      "100%|██████████| 50/50 [01:02<00:00,  1.26s/it]\n",
      "100%|██████████| 50/50 [01:02<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spatial_3d_prompt = [\n",
    "    \"a sofa in front of a plate\",\n",
    "    \"a horse hidden by a television\",\n",
    "    \"a fish behind a butterfly\",\n",
    "    \"a book hidden by a wallet\",\n",
    "    \"a microwave behind a bowl\",\n",
    "    \"a cat hidden by a airplane\",\n",
    "    \"a refrigerator behind a candle\",\n",
    "    \"a desk hidden by a bowl\",\n",
    "    \"a train hidden by a bird\",\n",
    "    \"a key in front of a bicycle\"\n",
    "]\n",
    "for prompt in spatial_3d_prompt:\n",
    "    image = pipe(prompt).images[0]  \n",
    "    image.save(f\"{prompt}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa0ddb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n",
      "100%|██████████| 50/50 [00:56<00:00,  1.13s/it]\n",
      "100%|██████████| 50/50 [00:58<00:00,  1.17s/it]\n",
      "100%|██████████| 50/50 [00:56<00:00,  1.13s/it]\n",
      "100%|██████████| 50/50 [00:55<00:00,  1.12s/it]\n",
      "100%|██████████| 50/50 [00:55<00:00,  1.11s/it]\n",
      "100%|██████████| 50/50 [00:58<00:00,  1.17s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n",
      "100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n",
      "100%|██████████| 50/50 [00:58<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "spatial_prompt = [\n",
    "    \"a balloon on the top of a giraffe\",\n",
    "    \"a suitcase on the top of a frog\",\n",
    "    \"a horse on the right of a man\",\n",
    "    \"a rabbit next to a balloon\",\n",
    "    \"a rabbit on the top of a bicycle\",\n",
    "    \"a bee on the left of a girl\",\n",
    "    \"a mouse on the bottom of a painting\",\n",
    "    \"a fish on side of a painting\",\n",
    "    \"a chicken on the bottom of a desk\",\n",
    "    \"a chicken near a desk\"\n",
    "]\n",
    "\n",
    "for prompt in spatial_prompt:\n",
    "    image = pipe(prompt).images[0]  \n",
    "    image.save(f\"./spatial/{prompt}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "816daeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n",
      "100%|██████████| 50/50 [00:58<00:00,  1.16s/it]\n",
      "100%|██████████| 50/50 [01:04<00:00,  1.30s/it]\n",
      "100%|██████████| 50/50 [01:11<00:00,  1.44s/it]\n",
      "100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n",
      "100%|██████████| 50/50 [01:00<00:00,  1.21s/it]\n",
      "100%|██████████| 50/50 [01:08<00:00,  1.36s/it]\n",
      "100%|██████████| 50/50 [01:10<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "polygon_spatial = [\n",
    "    \"a red circle above a blue square\",\n",
    "    \"a blue circle below a red square\",\n",
    "    \"a blue square to the left of a green circle\",\n",
    "    \"a green circle to the left of a blue square\",\n",
    "    \"a red square above a blue circle\",\n",
    "    \"a red square below a green circle\",\n",
    "    \"a blue square below a red circle\",\n",
    "    \"a blue circle above a red square\",\n",
    "]\n",
    "\n",
    "for prompt in polygon_spatial:\n",
    "    image = pipe(prompt).images[0]  \n",
    "    image.save(f\"./polygon_spatial/{prompt}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed8b25c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwell shaped girl wearing bikini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]  \n\u001b[1;32m      2\u001b[0m image\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:1061\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.__call__\u001b[0;34m(self, prompt, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m rescale_noise_cfg(noise_pred, noise_pred_text, guidance_rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguidance_rescale)\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_step_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback_on_step_end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     callback_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/diffusers/schedulers/scheduling_pndm.py:256\u001b[0m, in \u001b[0;36mPNDMScheduler.step\u001b[0;34m(self, model_output, timestep, sample, return_dict)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_prk(model_output\u001b[38;5;241m=\u001b[39mmodel_output, timestep\u001b[38;5;241m=\u001b[39mtimestep, sample\u001b[38;5;241m=\u001b[39msample, return_dict\u001b[38;5;241m=\u001b[39mreturn_dict)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_plms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/diffusers/schedulers/scheduling_pndm.py:379\u001b[0m, in \u001b[0;36mPNDMScheduler.step_plms\u001b[0;34m(self, model_output, timestep, sample, return_dict)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m24\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m55\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m59\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m37\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m--> 379\u001b[0m prev_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_prev_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_timestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/diffusers/schedulers/scheduling_pndm.py:425\u001b[0m, in \u001b[0;36mPNDMScheduler._get_prev_sample\u001b[0;34m(self, sample, timestep, prev_timestep, model_output)\u001b[0m\n\u001b[1;32m    423\u001b[0m alpha_prod_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod[timestep]\n\u001b[1;32m    424\u001b[0m alpha_prod_t_prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod[prev_timestep] \u001b[38;5;28;01mif\u001b[39;00m prev_timestep \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_alpha_cumprod\n\u001b[0;32m--> 425\u001b[0m beta_prod_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_prod_t\u001b[49m\n\u001b[1;32m    426\u001b[0m beta_prod_t_prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_prod_t_prev\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/torch/_tensor.py:43\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     sargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, sargs, \u001b[38;5;241m*\u001b[39msargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image = pipe(\"well shaped girl wearing bikini\", step=100).images[0]  \n",
    "image.save(f\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484dd059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionModel(\n",
      "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (time_proj): Timesteps()\n",
      "  (time_embedding): TimestepEmbedding(\n",
      "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "    (act): SiLU()\n",
      "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  )\n",
      "  (down_blocks): ModuleList(\n",
      "    (0): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): CrossAttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleList(\n",
      "    (0): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-2): 3 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): CrossAttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Transformer2DModel(\n",
      "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (transformer_blocks): ModuleList(\n",
      "            (0): BasicTransformerBlock(\n",
      "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn1): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn2): Attention(\n",
      "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                (to_out): ModuleList(\n",
      "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "              (ff): FeedForward(\n",
      "                (net): ModuleList(\n",
      "                  (0): GEGLU(\n",
      "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                  )\n",
      "                  (1): Dropout(p=0.0, inplace=False)\n",
      "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid_block): UNetMidBlock2DCrossAttn(\n",
      "    (attentions): ModuleList(\n",
      "      (0): Transformer2DModel(\n",
      "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (transformer_blocks): ModuleList(\n",
      "          (0): BasicTransformerBlock(\n",
      "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn1): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn2): Attention(\n",
      "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "              (to_out): ModuleList(\n",
      "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "            (ff): FeedForward(\n",
      "              (net): ModuleList(\n",
      "                (0): GEGLU(\n",
      "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                )\n",
      "                (1): Dropout(p=0.0, inplace=False)\n",
      "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (resnets): ModuleList(\n",
      "      (0-1): 2 x ResnetBlock2D(\n",
      "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "  (conv_act): SiLU()\n",
      "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Number of parameters in pipe.unet: 859520964\n"
     ]
    }
   ],
   "source": [
    "# for name, module in pipe.unet.named_modules():\n",
    "#     for block_name in [\"up\", \"mid\", \"down\"]:\n",
    "#         for atten_id in [\"attn1\", \"attn2\"]:\n",
    "#             if block_name in name and atten_id in name:\n",
    "#                 module.to_q._name = f\"{block_name}_{atten_id}_to_q\"\n",
    "#                 module.to_k._name = f\"{block_name}_{atten_id}_to_k\"\n",
    "#                 module.to_v._name = f\"{block_name}_{atten_id}_to_v\"\n",
    "#                 module.to_out[0]._name = f\"{block_name}_{atten_id}_to_out\"\n",
    "\n",
    "print(pipe.unet)\n",
    "num_params = sum(p.numel() for p in pipe.unet.parameters())\n",
    "print(f\"Number of parameters in pipe.unet: {num_params}\")\n",
    "# print(pipe.vae)           \n",
    "# print(pipe.text_encoder)  \n",
    "# print(pipe.tokenizer)     \n",
    "# print(pipe.scheduler)     \n",
    "# print(pipe.safety_checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732b9d5",
   "metadata": {},
   "source": [
    "down_blocks\n",
    "  CrossAttn 0, 1, 2\n",
    "  DownBlock 3\n",
    "up_blocks\n",
    "  UpBlock 0\n",
    "  CrossAttn 1, 2, 3\n",
    "mid_block\n",
    "  CrossAttn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0837c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q',\n",
       " 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k',\n",
       " 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v',\n",
       " 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0',\n",
       " 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q',\n",
       " 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k',\n",
       " 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v',\n",
       " 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0',\n",
       " 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q',\n",
       " 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k',\n",
       " 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v',\n",
       " 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# up_blocks, down_blocks, mid_block\n",
    "# 0, 1, 2, 3\n",
    "# attn1, attn2\n",
    "def get_target_modules_attn(block_name, block_ids, attn_id):\n",
    "    target_modules = []\n",
    "    for block_id in block_ids:\n",
    "        for proj in ['to_q', 'to_k', 'to_v', 'to_out.0']:\n",
    "            path = block_name + '.' + str(block_id) + '.attentions.0.transformer_blocks.0.' + attn_id + '.' + proj\n",
    "            target_modules.append(path)\n",
    "\n",
    "    return target_modules\n",
    "\n",
    "get_target_modules_attn(\"up_blocks\", [1, 2, 3], \"attn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): UNet2DConditionModel(\n",
      "      (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (time_proj): Timesteps()\n",
      "      (time_embedding): TimestepEmbedding(\n",
      "        (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "        (act): SiLU()\n",
      "        (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      )\n",
      "      (down_blocks): ModuleList(\n",
      "        (0): CrossAttnDownBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0-1): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0-1): 2 x ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (downsamplers): ModuleList(\n",
      "            (0): Downsample2D(\n",
      "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CrossAttnDownBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0-1): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (downsamplers): ModuleList(\n",
      "            (0): Downsample2D(\n",
      "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CrossAttnDownBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0-1): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (downsamplers): ModuleList(\n",
      "            (0): Downsample2D(\n",
      "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): DownBlock2D(\n",
      "          (resnets): ModuleList(\n",
      "            (0-1): 2 x ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (up_blocks): ModuleList(\n",
      "        (0): UpBlock2D(\n",
      "          (resnets): ModuleList(\n",
      "            (0-2): 3 x ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (upsamplers): ModuleList(\n",
      "            (0): Upsample2D(\n",
      "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CrossAttnUpBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0): Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=1280, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=1280, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_k): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=1280, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=1280, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=1280, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=1280, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=1280, out_features=4, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=4, out_features=1280, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                        (lora_magnitude_vector): ModuleDict()\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0-1): 2 x ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (2): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (upsamplers): ModuleList(\n",
      "            (0): Upsample2D(\n",
      "              (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CrossAttnUpBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0): Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=640, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=640, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_k): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=640, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=640, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=640, out_features=640, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=640, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=640, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=640, out_features=4, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=4, out_features=640, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                        (lora_magnitude_vector): ModuleDict()\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=640, out_features=640, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=2560, out_features=640, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (2): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
      "              (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (upsamplers): ModuleList(\n",
      "            (0): Upsample2D(\n",
      "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): CrossAttnUpBlock2D(\n",
      "          (attentions): ModuleList(\n",
      "            (0): Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=320, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=320, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_k): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=320, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=320, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=320, out_features=320, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.1, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=320, out_features=4, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=4, out_features=320, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                      (lora_magnitude_vector): ModuleDict()\n",
      "                    )\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): lora.Linear(\n",
      "                        (base_layer): Linear(in_features=320, out_features=320, bias=True)\n",
      "                        (lora_dropout): ModuleDict(\n",
      "                          (default): Dropout(p=0.1, inplace=False)\n",
      "                        )\n",
      "                        (lora_A): ModuleDict(\n",
      "                          (default): Linear(in_features=320, out_features=4, bias=False)\n",
      "                        )\n",
      "                        (lora_B): ModuleDict(\n",
      "                          (default): Linear(in_features=4, out_features=320, bias=False)\n",
      "                        )\n",
      "                        (lora_embedding_A): ParameterDict()\n",
      "                        (lora_embedding_B): ParameterDict()\n",
      "                        (lora_magnitude_vector): ModuleDict()\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x Transformer2DModel(\n",
      "              (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
      "              (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (transformer_blocks): ModuleList(\n",
      "                (0): BasicTransformerBlock(\n",
      "                  (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn1): Attention(\n",
      "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (attn2): Attention(\n",
      "                    (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
      "                    (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
      "                    (to_out): ModuleList(\n",
      "                      (0): Linear(in_features=320, out_features=320, bias=True)\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "                  (ff): FeedForward(\n",
      "                    (net): ModuleList(\n",
      "                      (0): GEGLU(\n",
      "                        (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
      "                      )\n",
      "                      (1): Dropout(p=0.0, inplace=False)\n",
      "                      (2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (resnets): ModuleList(\n",
      "            (0): ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (1-2): 2 x ResnetBlock2D(\n",
      "              (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
      "              (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
      "              (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (nonlinearity): SiLU()\n",
      "              (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mid_block): UNetMidBlock2DCrossAttn(\n",
      "        (attentions): ModuleList(\n",
      "          (0): Transformer2DModel(\n",
      "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
      "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (transformer_blocks): ModuleList(\n",
      "              (0): BasicTransformerBlock(\n",
      "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn1): Attention(\n",
      "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                  (to_out): ModuleList(\n",
      "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn2): Attention(\n",
      "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
      "                  (to_out): ModuleList(\n",
      "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "                (ff): FeedForward(\n",
      "                  (net): ModuleList(\n",
      "                    (0): GEGLU(\n",
      "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
      "                    )\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (resnets): ModuleList(\n",
      "          (0-1): 2 x ResnetBlock2D(\n",
      "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "            (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (nonlinearity): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
      "      (conv_act): SiLU()\n",
      "      (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of parameters in unet_lora_up_sa: 859592644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaimao/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/Users/kaimao/Desktop/Stable_Diffusion_Experiment/.venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "import peft\n",
    "\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=get_target_modules_attn(\"up_blocks\", [1, 2, 3], \"attn1\")\n",
    ")\n",
    "hug\n",
    "unet_lora_up_sa = get_peft_model(pipe.unet, lora_config)\n",
    "print(unet_lora_up_sa)\n",
    "num_params = sum(p.numel() for p in unet_lora_up_sa.parameters() if )\n",
    "print(f\"Number of parameters in unet_lora_up_sa: {num_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
